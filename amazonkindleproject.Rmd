---
title: "amazon kindle"
author: "Dharani, Nalabolu"
date: "11/13/2018"
output: html_document
---

```{r}
corpus<-corpus(VectorSource(amazonkindle$reviewText))
#text cleaning
View(corpus)
#convert the text to lower case
corpus <- tm_map(corpus,content_transformer(tolower))
inspect(corpus[1:20])
#remove nuymbers
corpus<- tm_map(corpus,removeNumbers)
#remove english common stopwords
corpus<- tm_map(corpus,removeWords,stopwords("english"))
#remove punctuation
corpus<-tm_map(corpus,removePunctuation)
#remove extra whitespaces
corpus<-tm_map(corpus,stripWhitespace)
#remove selected words from previous wordcloud search to get meani8ngful results
corpus<-tm_map(corpus,removeWords,c("this","the","was","and","you","but","her","this","that","she","with","book"))
```

#create term document matrix(matrix which describes the frequency of the terms)

```{r}

tdm<-TermDocumentMatrix(corpus)

tdm<-as.matrix(tdm)

tdm[1:10, 1:20]

v<-rowSums(tdm)

v<- subset(v, v>=30)

v< -sort(rowSums(tdm), decreasing= TRUE)

set.seed(222)

```



#word cloud
```{r}

wordcloud(names(v), freq = v, max.words=1000, 
          random.order = FALSE, 
          min.freq =5,colors= rainbow(50),
rot.per= 0.7)
```

#data frame
```{r}

V<-data.frame(names(v),v)

colnames(v) <- c("word","freq")

```


# sentimental analysis 
```{r}

library(syuzhet)
library(lubridate)

s <- get_nrc_sentiment(amazonkindle$reviewText)

barplot(colSums(s), las=2, col= rainbow(10), ylab= 'Count', main = 'sentiment analysis of amazon kindle')
```




